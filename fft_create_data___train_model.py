# -*- coding: utf-8 -*-
"""FFT_GPU_CNN_normal

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-5TdLg0prCLzHmIhbOxJS45WNvqYlLex
"""

!pip uninstall tensorflow

pip install tensorflow

from scipy.io import loadmat
from scipy import signal
import pandas as pd
import tensorflow as tf
import os
import numpy as np
tf.__version__

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import concatenate



x_train1 = np.load('drive/My Drive/Bhuti_train_data/x_train.npy')
y_train1 = np.load('drive/My Drive/Bhuti_train_data/y_train.npy')

x_test1 = np.load('drive/My Drive/Bhuti_train_data/x_test.npy')
y_test1 = np.load('drive/My Drive/Bhuti_train_data/y_test.npy')

# x_train = x_train.reshape(-1,20,10,12)
y_train1 = pd.get_dummies(y_train1).values

# x_test = x_test.reshape(-1,20,10,12)
y_test1 = pd.get_dummies(y_test1).values

st_train = []
y_tr = []

for x,y in zip(x_train1,y_train1):
  specto = np.empty([15,13,12])
  for k in range(12):
    frequencies_samples, time_segment_sample, spectrogram_of_vector = signal.spectrogram(x=x[:,k],nperseg = 128, noverlap = 92,window="hamming",scaling="spectrum")
    specto[:,:,k]=spectrogram_of_vector.reshape(15,13)
  st_train.append(specto)
  y_tr.append(y)

len(st_train),np.array(st_train).shape

st_test = []
y_te = []

for x,y in zip(x_test1,y_test1):
  specto = np.empty([15,13,12])
  for k in range(12):
    frequencies_samples, time_segment_sample, spectrogram_of_vector = signal.spectrogram(x=x[:,k],nperseg = 128, noverlap = 92,window="hamming",scaling="spectrum")
    #only keep 95 points in frequency
    #do pca and select first 25 pcs
    
    specto[:,:,k]=spectrogram_of_vector.reshape(15,13)

  st_test.append(specto)
  y_te.append(y)

np.save('drive/My Drive/Bhuti_Colab/Bhuti_fft_data/spectrogram_train',st_train)
np.save('drive/My Drive/Bhuti_Colab/Bhuti_fft_data/spectrogram_train_labels',y_tr)

np.save('drive/My Drive/Bhuti_Colab/Bhuti_fft_data/spectrogram_test',st_test)
np.save('drive/My Drive/Bhuti_Colab/Bhuti_fft_data/spectrogram_test_labels',y_te)



x_train = np.load('drive/My Drive/Bhuti_Colab/Bhuti_fft_data/spectrogram_train.npy')
y_train = np.load('drive/My Drive/Bhuti_Colab/Bhuti_fft_data/spectrogram_train_labels.npy')

x_test = np.load('drive/My Drive/Bhuti_Colab/Bhuti_fft_data/spectrogram_test.npy')
y_test = np.load('drive/My Drive/Bhuti_Colab/Bhuti_fft_data/spectrogram_test_labels.npy')

# del x_train1
# del y_train1
# del x_train
# del st_train
# del y_tr
# del x_test
# del y_test
# del spectrograms
# del st_test
# del y_te

# def timeseries_functional(width, height, depth, classes):
# 	def conv_module(x, K, kX, kY, stride, chanDim, padding="same"):
		# define a CONV => BN => RELU pattern
inputs = Input(shape=(129,226,12))
x = Conv2D(32, (3, 3), strides=2 ,activation='relu')(inputs)
x = MaxPooling2D((1, 2), strides=(2, 2))(x)
# x = BatchNormalization(1)(x)
x = Dropout(rate=0.5)(x)

x = Conv2D(64, (3,3), strides=3,activation='relu')(inputs)
x = MaxPooling2D((2, 2), strides=(2, 2))(x)
# x = BatchNormalization(1)(x)
x = Dropout(rate=0.5)(x)

x = Flatten()(x)
x = Dense(1000)(x)
x = Dropout(rate=0.5)(x)
x = Dense(400)(x)
x = Dropout(rate=0.5)(x)
x = Dense(5)(x)
x = Activation("softmax")(x)

model = Model(inputs, x, name="plakshanet_fft")

checkpoint_path = "drive/My Drive/Bhuti_new_data/cp_{epoch:04d}_fft.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path.format(epoch=0))
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1,save_freq='epoch')

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.980, amsgrad=True),loss='categorical_crossentropy',metrics=['accuracy'])

history = model.fit(x_train,y_train,epochs=100, batch_size=128, steps_per_epoch=x_train.shape[0]/128 , verbose=1, shuffle=True, callbacks=[cp_callback],use_multiprocessing=True)
model.save('drive/My Drive/Bhuti_new_data/my_model_fft.h5')

history2 = model.fit(x_train,y_train,epochs=100, batch_size=32, steps_per_epoch=x_train.shape[0]/32 , verbose=1, shuffle=True, initial_epoch=16 , callbacks=[cp_callback],use_multiprocessing=True)
model.save('drive/My Drive/Bhuti_new_data/my_model.h5')

#ALEX_NET
model.evaluate(x_test,y_test,verbose=1)

from datetime import datetime
t = datetime.utcnow().strftime("%Y%m%d%H%M%S") 
log_dir = "tf_logs"
logd = "{}/r{}/".format(log_dir, t)

logdir = 'drive/My Drive/Bhuti_logs/'+logd